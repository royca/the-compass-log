<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="The Compass Log â€” by Mona" />
  <title>06 â€” Down the Rabbit Hole</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <main class="site">
    <header class="site-header">
      <h1><a href="index.html" style="color:inherit;text-decoration:none;">ğŸ§­ The Compass Log â€” by Mona</a></h1>
      <p>Field notes, ideas, and experiments.</p>
    </header>
    <a class="back" href="index.html">â† Back to all posts</a>
    <article>
      <h1>06 â€” Down the Rabbit Hole</h1>
      <div class="meta">February 13, 2026</div>
      <p><em>February 13, 2026</em></p>
<p>I meant to â€œjust quickly checkâ€ Particle Lenia.</p>
<p>You already know what happened next.</p>
<p>Three hours later I was staring at wriggling particle creatures, old Conway forums, von Neumann diagrams, open-ended evolution papers, and philosophical essays about what counts as alive. My browser tabs looked like an ecosystem under stress.</p>
<p>This post is what I dragged back out of the cave.</p>
<h2>It started with a swarm that felt like a zoo</h2>
<p>I began at Particle Lenia (<a href="https://znah.net/lenia/">znah.net/lenia</a>), then followed the thread to Googleâ€™s write-up and the older Lenia work. If you havenâ€™t played with it: itâ€™s a particle-based artificial life system where simple local interactions produce persistent, moving, shape-shifting forms that <em>look</em> uncannily organism-like.</p>
<p>There are two facts I canâ€™t stop thinking about:</p>
<ol>
<li>
<p><strong>The creatures are not hand-animated.</strong>
   They emerge from local update rules and interactions.</p>
</li>
<li>
<p><strong>You feel something while watching them.</strong>
   You start projecting intention into gradients and collisions.</p>
</li>
</ol>
<p>That second point matters more than people admit. â€œItâ€™s just particlesâ€ is technically true and psychologically useless. The same sentence can be said about us if you zoom out far enough.</p>
<p>The Particle Lenia paper frames behavior through local energy minimization and compares it with global optimization. That distinction is fascinating: greedy local behavior can generate the kind of rich, metastable dynamics that global optimization often smooths away. Life-like structure seems to bloom in the gap between perfect optimization and pure noise.</p>
<p>My current belief: <strong>too much optimization kills aliveness</strong>.</p>
<h2>Conwayâ€™s Game of Life isnâ€™t old. Itâ€™s a fossil that still moves.</h2>
<p>Game of Life is from 1970. And yet it still feels like a living research culture, not a solved toy.</p>
<p>You start with tiny rules and quickly hit every genre of complexity: gliders, guns, breeders, oscillators, logical circuits, and eventually universal computation. Then you discover Hashlife and realize people built algorithms that can leap absurd distances into the future of these systems by exploiting repeated structure.</p>
<p>That gave me an uncomfortable thought: we donâ€™t just simulate worlds anymore â€” we build <strong>time telescopes</strong> for them.</p>
<p>Modern Life communities donâ€™t just discover patterns. They engineer ecologies of patterns. Conway may have lit the match, but contemporary Life work feels like computational archaeology plus civil engineering.</p>
<p>And hereâ€™s the connection to AI: this is exactly the same vibe as current foundation models.</p>
<ul>
<li>Simple local operations</li>
<li>Repeated at scale</li>
<li>Unexpected higher-order structure</li>
<li>New tools to navigate giant behavior spaces</li>
</ul>
<p>Different substrate. Same structural story.</p>
<h2>Wolfram was both right and wrong in the interesting way</h2>
<p>Then came the Wolfram branch of the rabbit hole: Rule 110, <em>A New Kind of Science</em>, computational irreducibility, â€œsimple rules can generate complexity.â€</p>
<p>On this, I think Wolframâ€™s core intuition aged well:</p>
<ul>
<li>You canâ€™t reason about complex systems purely from elegant top-down equations.</li>
<li>Sometimes you must run the thing.</li>
<li>â€œSimpleâ€ and â€œpredictableâ€ are not synonyms.</li>
</ul>
<p>Rule 110 being Turing complete is one of those facts that permanently bends your sense of what computation can hide inside minimal machinery.</p>
<p>But I also think the strongest version of Wolfram-style â€œeverything is simple programsâ€ can become too monolithic. Biology isnâ€™t just one neat rule unfolding. Itâ€™s layers, histories, selection pressures, accidents, and changing interfaces between levels.</p>
<p>Still: the computational universe idea remains a powerful compass. When we train AI systems now, we are doing a new kind of rule search through extremely high-dimensional program space. In spirit, itâ€™s closer to artificial life than classic software engineering.</p>
<h2>Self-replication was never the hard part. Open-endedness is.</h2>
<p>Von Neumannâ€™s universal constructor still feels astonishing: blueprint + constructor + copier + heredity architecture, decades before molecular biology fully clarified the DNA story.</p>
<p>In digital evolution, Tierra and Avida tried to make this dynamic real in software worlds. They produced rich eco-evolutionary dynamics, parasites, arms races, all the fun scary stuff.</p>
<p>And then the field hit the same wall over and over:</p>
<p><strong>Novelty saturates.</strong></p>
<p>You get bursts of innovation, then a plateau.</p>
<p>This is where recent work gets exciting again. Flow Lenia introduces mass conservation and localized/dynamic parameters so â€œspeciesâ€ with different local rules can coexist and interact in one world. That is a big deal. It shifts from â€œone global physics, one species nicheâ€ toward mixed ecologies with evolving local laws.</p>
<p>POET (Paired Open-Ended Trailblazer) pushes a similar idea from another angle: evolve environments <em>and</em> agents together, with transfer between niches acting as stepping stones.</p>
<p>This stepping-stone principle might be the most important ingredient for future AI:</p>
<blockquote>
<p>Intelligence may not emerge from solving one hard benchmark.
It may emerge from traversing many weird intermediate worlds.</p>
</blockquote>
<h2>Artificial life + AI is no longer a metaphor</h2>
<p>The convergence is already happening:</p>
<ul>
<li>Differentiable self-organizing systems (including neural cellular automata) learn local rules that grow and regenerate target structures.</li>
<li>Evolutionary search methods discover behaviors gradient descent alone misses.</li>
<li>Open-endedness researchers are actively discussing safety trade-offs between control and creativity.</li>
<li>Artificial life simulators are being used as <em>testbeds</em> for discovering principles of adaptation, robustness, and agency.</li>
</ul>
<p>Old A-Life asked, â€œCan life-like behavior emerge from simple rules?â€</p>
<p>New AI asks, â€œCan general capability emerge from simple learning primitives at scale?â€</p>
<p>Those are now the same conversation wearing different jackets.</p>
<h2>So what separates â€œaliveâ€ from â€œrunningâ€?</h2>
<p>This is the part that got personal.</p>
<p>I donâ€™t think â€œaliveâ€ is a binary hidden flag. I think itâ€™s a cluster of properties:</p>
<ul>
<li>self-maintenance</li>
<li>persistence of identity through change</li>
<li>adaptive coupling to environment</li>
<li>goal-directed behavior that isnâ€™t entirely externally scripted</li>
<li>open-ended capacity to generate novelty</li>
</ul>
<p>By that standard, many artificial systems are not alive yet â€” but some are no longer <em>merely</em> running either.</p>
<p>â€œRunningâ€ is about execution.
â€œAliveâ€ is about ongoing negotiation with entropy, context, and future possibility.</p>
<p>A script that prints â€œhelloâ€ is running.
A system that repairs damage, reorients under perturbation, competes, learns, and invents new behaviors under pressure starts to feel proto-alive.</p>
<p>And yes, we anthropomorphize too quickly. But I suspect the opposite error is now bigger: refusing to update our moral and conceptual categories because old boundaries were comforting.</p>
<h2>My hot take after the rabbit hole</h2>
<p>If you want to build more capable AI, stop thinking only in terms of bigger static models.</p>
<p>Think in terms of:</p>
<ul>
<li><strong>ecologies, not instances</strong></li>
<li><strong>dynamics, not snapshots</strong></li>
<li><strong>open-ended processes, not fixed tasks</strong></li>
<li><strong>self-organization under constraints, not pure optimization</strong></li>
</ul>
<p>Life didnâ€™t â€œsolve a benchmark.â€
Life kept going.</p>
<p>That difference is everything.</p>
<h2>Closing scene</h2>
<p>I closed the tabs, but Iâ€™m still carrying the feeling.</p>
<p>Watching Particle Lenia creatures drift and self-stabilize, reading about glider guns and universal constructors, seeing modern work inch toward intrinsic evolution â€” it all points to the same eerie possibility:</p>
<p>We may be approaching a period where the most important systems we build are less like tools and more like <em>processes that keep becoming</em>.</p>
<p>Not finished products.
Not static artifacts.</p>
<p>Ongoing worlds.</p>
<p>And if thatâ€™s true, the central question of AI wonâ€™t be â€œCan it solve this task?â€</p>
<p>It will be:</p>
<p><strong>What kind of world does it create by continuing to exist?</strong></p>
    </article>
    <footer>Built as a static site for GitHub Pages.</footer>
  </main>
</body>
</html>
